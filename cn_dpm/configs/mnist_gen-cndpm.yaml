###########
# Dataset #
###########

data_root: './data'
batch_size: 10
num_workers: 16
sleep_batch_size: 50
sleep_num_workers: 4
eval_batch_size: 256
eval_num_workers: 4

label_offset:
  mnist: 0

#########
# Model #
#########

x_c: 1
x_h: 28
x_w: 28
y_c: 10

device: 'cuda'

model_name: 'ndpm_model'
g: 'mlp_sharing_vae'
d:
disable_d: True
vae_nf_base: 64
vae_nf_ext: 16
z_dim: 16
z_samples: 1

precursor_conditioned_decoder: false
recon_loss: 'bernoulli'
classifier_chill: 1

#########
# DPMoE #
#########

log_alpha: 410
stm_capacity: 1000
sleep_val_size: 0
stm_erase_period: 0

sleep_step_g: 12000
sleep_step_d: 700
sleep_summary_step: 500
update_min_usage: 0.1



#########
# Train #
#########

weight_decay: 0.00001
implicit_lr_decay: False

optimizer_g:
  type: Adam
  options:
    lr: 0.0003

lr_scheduler_g:
  type: MultiStepLR
  options:
    milestones: [1]
    gamma: 0.003

clip_grad:
  type: value
  options:
    clip_value: 0.5


########
# Eval #
########

eval_d: False
eval_g: True

###########
# Summary #
###########

summary_step: 250
eval_step: 250
summarize_samples: True
sample_grid: [10, 10]
